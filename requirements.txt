# Core dependencies for multi-GPU Qwen3 server
# NOTE: llama-cpp-python is installed separately with CUDA support
# DO NOT install from requirements.txt - see installation instructions
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.5.0
requests>=2.31.0
huggingface-hub>=0.19.0
jinja2>=3.1.0

# CLI and utilities
rich>=13.7.0
tqdm>=4.66.0
click>=8.1.0

# System monitoring
psutil>=5.9.0
numpy>=1.24.0

# Logging and configuration
pyyaml>=6.0.0
python-json-logger>=2.0.0

# Optional: GPU monitoring
pynvml>=11.5.0 